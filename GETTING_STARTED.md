# Getting Started with SAMI

Este guia vai te ajudar a come√ßar a usar o SAMI para identifica√ß√£o autom√°tica de esponjas do Cambriano.

## 1. Instala√ß√£o

### Pr√©-requisitos
- Python 3.8 ou superior
- CUDA (opcional, mas recomendado para GPU)

### Instalar Depend√™ncias

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente
# No Windows:
venv\Scripts\activate
# No Linux/Mac:
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt
```

## 2. Preparar Seus Dados

### Estrutura de Diret√≥rios

Organize suas imagens de esponjas da seguinte forma:

```
imagefolder_cambrian_sponges/
‚îú‚îÄ‚îÄ Archaeocyatha_species1/
‚îÇ   ‚îú‚îÄ‚îÄ specimen_001.jpg
‚îÇ   ‚îú‚îÄ‚îÄ specimen_002.jpg
‚îÇ   ‚îú‚îÄ‚îÄ specimen_003.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Porifera_species2/
‚îÇ   ‚îú‚îÄ‚îÄ specimen_001.jpg
‚îÇ   ‚îú‚îÄ‚îÄ specimen_002.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ Hexactinellida_species3/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

**Importante:**
- Cada pasta representa uma esp√©cie diferente
- O nome da pasta ser√° usado como o nome da classe
- Formatos suportados: `.jpg`, `.jpeg`, `.png`
- Recomendado: pelo menos 20-30 imagens por esp√©cie para resultados confi√°veis

## 3. Primeiros Passos

### Op√ß√£o A: Come√ßar do Zero (Sem Modelo Pr√©-treinado)

Se voc√™ ainda n√£o tem um modelo treinado:

```bash
# 1. Testar o exemplo b√°sico
python example_usage.py

# 2. Extrair features da sua base de dados
# (Edite example_usage.py e descomente extract_database_features_example)
```

**Nota:** Sem um modelo pr√©-treinado, os resultados ser√£o aleat√≥rios. Voc√™ precisar√°:
1. Treinar um modelo do zero, OU
2. Fazer fine-tuning de um modelo SCAMPI pr√©-treinado

### Op√ß√£o B: Usar Modelo SCAMPI Como Ponto de Partida

Baixe os pesos do SCAMPI e use como base:

```bash
# Baixar pesos do SCAMPI ViT-S/16
wget https://huggingface.co/IverMartinsen/scampi-dino-vits16/resolve/main/vit_small_backbone.pth

# Rodar avalia√ß√£o
python run_evaluation.py \
    --data_path ./imagefolder_cambrian_sponges \
    --model_path ./vit_small_backbone.pth \
    --model_arch vit_small \
    --output_dir ./results
```

## 4. Entendendo os Resultados

Ap√≥s rodar `run_evaluation.py`, voc√™ encontrar√° em `./results/`:

### `evaluation_report.txt`
Resumo geral com m√©tricas principais:
- **Accuracy**: Acur√°cia geral
- **F1-Score**: M√©dia harm√¥nica de precis√£o e recall
- **Precision/Recall**: Por esp√©cie

### `confusion_matrix.png`
Matriz de confus√£o mostrando:
- Diagonal: Classifica√ß√µes corretas
- Fora da diagonal: Confus√µes entre esp√©cies

### `t-sne_visualization.png`
Visualiza√ß√£o 2D dos embeddings:
- Pontos pr√≥ximos = esp√©cimes visualmente similares
- Clusters bem separados = esp√©cies bem distingu√≠veis

### `class_metrics.csv`
M√©tricas detalhadas por esp√©cie

### `k_comparison.csv`
Performance com diferentes valores de K para KNN

## 5. Interpretando os Resultados

### Bons Resultados
- **Accuracy > 0.80**: Modelo est√° funcionando bem
- **F1-Score > 0.75**: Boa capacidade de classifica√ß√£o
- **Clusters separados no t-SNE**: Esp√©cies s√£o distingu√≠veis

### Resultados Ruins
- **Accuracy < 0.60**: Modelo precisa de mais dados ou treinamento
- **Confus√£o entre esp√©cies similares**: Normal, pode melhorar com mais dados
- **Clusters sobrepostos no t-SNE**: Esp√©cies s√£o muito similares visualmente

## 6. Pr√≥ximos Passos

### Se os resultados est√£o bons:
1. Extraia features para toda sua cole√ß√£o
2. Use para busca por similaridade (CBIR)
3. Documente seu pipeline

### Se os resultados est√£o ruins:
1. **Coletar mais dados**: Pelo menos 50+ imagens por esp√©cie
2. **Data Augmentation**: Adicionar rota√ß√µes, flips, zoom
3. **Fine-tuning**: Treinar o modelo especificamente para suas esponjas
4. **Revis√£o de labels**: Verificar se as classifica√ß√µes est√£o corretas

## 7. Troubleshooting

### Erro: "CUDA out of memory"
```bash
# Reduzir batch size
python run_evaluation.py --batch_size 16
```

### Erro: "No images found"
- Verifique a estrutura de pastas
- Confirme que as imagens t√™m extens√µes corretas (.jpg, .jpeg, .png)

### Resultados aleat√≥rios
- Voc√™ est√° usando modelo sem pesos pr√©-treinados
- Baixe pesos do SCAMPI ou treine seu pr√≥prio modelo

## 8. Exemplo Completo

```bash
# 1. Criar estrutura de dados
mkdir -p imagefolder_cambrian_sponges/Archaeocyatha_sp1
mkdir -p imagefolder_cambrian_sponges/Porifera_sp2

# 2. Copiar suas imagens para as pastas apropriadas
# (fa√ßa isso manualmente ou com script)

# 3. Baixar modelo base
wget https://huggingface.co/IverMartinsen/scampi-dino-vits16/resolve/main/vit_small_backbone.pth

# 4. Rodar avalia√ß√£o
python run_evaluation.py \
    --data_path ./imagefolder_cambrian_sponges \
    --model_path ./vit_small_backbone.pth \
    --model_arch vit_small \
    --img_size 224 \
    --batch_size 32 \
    --k_neighbors 7 \
    --output_dir ./results \
    --save_embeddings_path ./sponge_embeddings.npz

# 5. Ver resultados
cat results/evaluation_report.txt
```

## 9. Ajuda e Suporte

- **Issues**: Abra uma issue no GitHub
- **D√∫vidas**: Consulte o README.md principal
- **Paper SCAMPI**: https://doi.org/10.1016/j.aiig.2024.100080

## 10. Checklist Inicial

- [ ] Python e depend√™ncias instaladas
- [ ] Imagens organizadas em pastas por esp√©cie
- [ ] Pelo menos 20 imagens por esp√©cie
- [ ] Modelo pr√©-treinado baixado (opcional)
- [ ] `example_usage.py` executado com sucesso
- [ ] `run_evaluation.py` executado com sucesso
- [ ] Resultados revisados e entendidos

Pronto! Voc√™ est√° preparado para usar o SAMI! üßΩüî¨
